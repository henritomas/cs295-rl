# cs295-rl
Reinforcement Learning course handled by Dr. Prospero Naval

## PA 1
Implementation of Q-Learning, SARSA, and Cross-Entropy Method, 
and their evaluation on FrozenLake-v0 (slippery and non-slippery) and the Cliff Walking Environment.

### Algorithms
1. [**Q-Learning**](https://github.com/henritomas/cs295-rl/blob/master/%5BCS295%5D%20Q-Learning%20-%20Implementation.ipynb) : documented notebook implementation of q-learning.
2. [**SARSA**](https://github.com/henritomas/cs295-rl/blob/master/%5BCS295%5D%20SARSA%20-%20Implementation.ipynb) : documented notebook implementation of SARSA.
3. [**Cross-Entropy Method**](https://github.com/henritomas/cs295-rl/blob/master/%5BCS295%5D%20Cross-Entropy%20Method%20-%20Implementation.ipynb)

### Environments
1. OpenAI Gym's FrozenLake-v0 environment. Set `is_slippery=False` for deterministic version. 
2. [Cliff Walking Environment](https://github.com/henritomas/cs295-rl/blob/master/%5BCS295%5D%20Cliff%20Walking%20Environment.ipynb), as described in Sutton and Barto's book. Linked is a notebook on how the environment was coded.

### Comparison
[Comparison Notebook](https://github.com/henritomas/cs295-rl/blob/master/%5BCS295%5D%20Comparison_%20Q-Learning%2C%20SARSA%2C%20CEM.ipynb): comparisons between the performance of the algorithms, as well as variations of their hyperparameters.
